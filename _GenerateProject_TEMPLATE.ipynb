{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GENERATE A BACKEND PROJECT \n",
    "\n",
    "+ this notebook is a template to generate Backend-required files to view a project with the DataDiVR (preview or VR)\n",
    "+ the \"create a graph\" section is a template graph writing a required format (json) to then use the generate-project functions of the DataDiVR backend \n",
    "+ If you have multiple graphs with stored positions, colors etc which should go into one project, use the \"merge_graphs\" function below \n",
    "+ This will result in a dictionary which can be used with the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_graphs(graphs):\n",
    "    all_nodes = []\n",
    "    all_links = []\n",
    "    layouts = []\n",
    "\n",
    "    seen_nodes = set()  # To track seen node IDs\n",
    "    seen_links = set()  # To track seen links by a tuple of (source, target)\n",
    "\n",
    "    for graph in graphs:\n",
    "        # Process nodes for global and layout-specific lists\n",
    "        for node, attrs in graph.nodes(data=True):\n",
    "            if node not in seen_nodes:\n",
    "                annotation = attrs.get('annotation', [])\n",
    "                anntation_mod = {}\n",
    "                for k,v in annotation.items():\n",
    "                    anntation_mod[k] = [v]\n",
    "                all_nodes.append({'id': node, 'name': node, \n",
    "                                    'annotation': anntation_mod})\n",
    "                seen_nodes.add(node)\n",
    "\n",
    "        # Process links for global list, now with separate source and target\n",
    "        for ix,(source, target, attrs) in enumerate(graph.edges(data=True)):\n",
    "            if (source, target) not in seen_links:\n",
    "                # Assuming 'weight' might be an attribute you're interested in\n",
    "                # weight = attrs.get('weight', 1)  # Example, uncomment if needed\n",
    "                all_links.append({\n",
    "                    'id': ix,  # It's unclear how 'id' is determined; might need a unique strategy\n",
    "                    # 'w': weight,  # Uncomment if using weight\n",
    "                    'source': source,\n",
    "                    'target': target\n",
    "                })\n",
    "                seen_links.add((source, target))\n",
    "\n",
    "        # Prepare layout-specific nodes and links\n",
    "        layout_nodes = [{'nodecolor': attrs.get('nodecolor', ''),\n",
    "                         'pos': attrs.get('pos', []),\n",
    "                         'cluster': attrs.get('cluster',''),\n",
    "                         'id': node} for node, attrs in graph.nodes(data=True)\n",
    "                        ]\n",
    "        layout_links = [{'linkcolor': attrs.get('linkcolor', ''),\n",
    "                         'source': source,\n",
    "                         'target': target} for source, target, attrs in graph.edges(data=True)]\n",
    "\n",
    "        layouts.append({'nodes': layout_nodes, 'links': layout_links})\n",
    "\n",
    "    # Assuming the structure of the graphs are similar, and using the first graph as the base\n",
    "    graphlayouts = [graph.name for graph in graphs]\n",
    "    merged_structure = {\n",
    "        'directed': graphs[0].is_directed(),\n",
    "        'multigraph': graphs[0].is_multigraph(),\n",
    "        'graphtitle': graphs[0].graph.get(\"graphtitle\", \"\"),\n",
    "        'graphdesc': graphs[0].graph.get(\"graphdesc\", \"\"),\n",
    "        'graphlayouts': graphlayouts,\n",
    "        'annotationTypes': True,\n",
    "        'nodes': all_nodes,\n",
    "        'links': all_links,\n",
    "        'layouts': layouts\n",
    "    }\n",
    "\n",
    "    return merged_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 - Create Graphs with stored positions, colors etc. or use your own nx.Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nx.Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  10\n",
      "Number of Links:  42\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import json \n",
    "import os\n",
    "\n",
    "G = nx.random_geometric_graph(10,1)\n",
    "print(\"Number of nodes: \", len(G.nodes()))\n",
    "print(\"Number of Links: \", len(G.edges()))\n",
    "\n",
    "# ===============================================\n",
    "# GRAPH NAME AND DESCRIPTION - a string each\n",
    "# ===============================================\n",
    "G.name = \"_uploadtest-5\"\n",
    "G.graph['graphtitle'] = G.name\n",
    "G.graph['graphdesc'] = \"A toy graph for testing purposes. Number of nodes: \"+str(len(G.nodes()))+\", Links: \"+ str(len(G.edges()))+\".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create node anntotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# ANNOTATIONS FORMAT - new ! (dictionary)\n",
    "# ===============================================\n",
    "\n",
    "l_annotations_json = []\n",
    "d_degree = dict(G.degree())\n",
    "d_eigen = dict(nx.eigenvector_centrality(G))\n",
    "for g in G.nodes():\n",
    "    sublist = {\"Node\":g, \"Degree\":d_degree[g], \"Eigenv\": round(d_eigen[g],2)}\n",
    "    l_annotations_json.append(sublist)\n",
    "        \n",
    "d_annotations = dict(zip(G.nodes(), l_annotations_json))\n",
    "nx.set_node_attributes(G, d_annotations, name=\"annotation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create node positions and set as \"pos\" Graph attribute \n",
    "here are 3 different layouts, which all are stored in unique nx.Graph-objects (G_rgba, G_hex, ....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layout (i.e. Graph 1)\n",
    "G_rgba = G.copy()\n",
    "G_rgba.name = 'layout1-spring'\n",
    "posG3D_1_pre = nx.spring_layout(G, dim=3, k=0.1, iterations=100)\n",
    "posG3D_1 = {key: value.tolist() for key, value in posG3D_1_pre.items()}\n",
    "nx.set_node_attributes(G_rgba, posG3D_1, name=\"pos\")\n",
    "\n",
    "\n",
    "# Second layout (i.e. Graph 2)\n",
    "G_hex = G.copy()\n",
    "G_hex.name = 'layout2-spring'\n",
    "posG3D_2_pre = nx.spring_layout(G, dim=3, k=0.1, iterations=200)\n",
    "posG3D_2= {key: value.tolist() for key, value in posG3D_2_pre.items()}\n",
    "nx.set_node_attributes(G_hex, posG3D_2, name=\"pos\")\n",
    "\n",
    "\n",
    "# Third layout (i.e. Graph 3)\n",
    "G_hex8 = G.copy()\n",
    "G_hex8.name = 'layout3-spring'\n",
    "posG3D_3_pre = nx.spring_layout(G, dim=3, k=0.1, iterations=500)\n",
    "posG3D_3 = {key: value.tolist() for key, value in posG3D_3_pre.items()}\n",
    "nx.set_node_attributes(G_hex8, posG3D_3, name=\"pos\")\n",
    "\n",
    "\n",
    "# Fourth layout (i.e. Graph 4) - with clusters\n",
    "G_clusters = G.copy()\n",
    "G_clusters.name = 'layout4-clusters'\n",
    "clustername_1 = 'cluster group 1'\n",
    "clustername_2 = 'cluster group 2'\n",
    "clustername_3 = 'cluster group 3'\n",
    "\n",
    "# nodes into groups\n",
    "for g in G_clusters.nodes():\n",
    "    if g < len(G_clusters.nodes()) / 3:\n",
    "        G_clusters.nodes[g]['cluster'] = clustername_1\n",
    "    elif g < 2 * len(G_clusters.nodes()) / 3:\n",
    "        G_clusters.nodes[g]['cluster'] = clustername_2\n",
    "    else:\n",
    "        G_clusters.nodes[g]['cluster'] = clustername_3\n",
    "\n",
    "nx.set_node_attributes(G_clusters, posG3D_2, name=\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get node attributes \n",
    "#node_attributes = nx.get_node_attributes(G_clusters, 'pos')\n",
    "#print(node_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### node and link colors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Formats of colors values are supported: hex, rgba, hex8\n",
    "\n",
    "# FIRST GRAPH - rgba color values\n",
    "d_nodecolors_rgba = dict(zip(G_rgba.nodes(),[(255,35,0,120)]*len(G_rgba.nodes())))\n",
    "nx.set_node_attributes(G_rgba, d_nodecolors_rgba, name=\"nodecolor\")\n",
    "l_linkcolors_rgba = (0,255,0,100)\n",
    "nx.set_edge_attributes(G_rgba, l_linkcolors_rgba, name=\"linkcolor\")\n",
    "\n",
    "\n",
    "# SECOND GRAPH - hex color values \n",
    "d_nodecolors_hex = dict(zip(G_hex.nodes(),['#FF2300']*len(G_hex.nodes())))\n",
    "nx.set_node_attributes(G_hex, d_nodecolors_hex, name=\"nodecolor\")\n",
    "l_linkcolors_hex = '#ff0000'\n",
    "nx.set_edge_attributes(G_hex, l_linkcolors_hex, name=\"linkcolor\")\n",
    "\n",
    "\n",
    "# THIRD GRAPH - hex8 color values\n",
    "d_nodecolors_hex8 = dict(zip(G_hex8.nodes(),['#0000ffaa']*len(G_hex8.nodes())))\n",
    "nx.set_node_attributes(G_hex8, d_nodecolors_hex8, name=\"nodecolor\")\n",
    "l_linkcolors_hex8 = '#0080ffaa'\n",
    "nx.set_edge_attributes(G_hex8, l_linkcolors_hex8, name=\"linkcolor\")\n",
    "\n",
    "\n",
    "# FOURTH GRAPH - clusters assigned \n",
    "\n",
    "# node colors \n",
    "d_nodecolors_clusters = {}\n",
    "nodes_group1 = []\n",
    "nodes_group2 = []\n",
    "nodes_group3 = []\n",
    "for n in G_clusters.nodes(): \n",
    "    if G_clusters.nodes[n]['cluster'] == clustername_1:\n",
    "        d_nodecolors_clusters[n] = '#0000ffaa'\n",
    "        nodes_group1.append(n)\n",
    "    elif G_clusters.nodes[n]['cluster'] == clustername_2:\n",
    "        d_nodecolors_clusters[n] = '#00ff00aa'\n",
    "        nodes_group2.append(n)\n",
    "    elif G_clusters.nodes[n]['cluster'] == clustername_3:\n",
    "        d_nodecolors_clusters[n] = '#ff0000aa'\n",
    "        nodes_group3.append(n)\n",
    "\n",
    "# link colors\n",
    "d_linkcolors_clusters = {}\n",
    "for edge in G_clusters.edges():\n",
    "    if edge[0] in nodes_group1 and edge[1] in nodes_group1:\n",
    "        d_linkcolors_clusters[edge] = '#0000ff'\n",
    "       \n",
    "    elif edge[0] in nodes_group2 and edge[1] in nodes_group2:\n",
    "        d_linkcolors_clusters[edge] = '#00ff00'\n",
    "       \n",
    "    elif edge[0] in nodes_group3 and edge[1] in nodes_group3:\n",
    "        d_linkcolors_clusters[edge] = '#ff0000'\n",
    "       \n",
    "    else:\n",
    "        d_linkcolors_clusters[edge] = '#B1B1B1'\n",
    "\n",
    "l_linkcolors_clusters = list(d_linkcolors_clusters.values())\n",
    "\n",
    "nx.set_node_attributes(G_clusters, d_nodecolors_clusters, name=\"nodecolor\")\n",
    "nx.set_edge_attributes(G_clusters, {edge: color for edge, color in zip(G_clusters.edges(), l_linkcolors_clusters)}, \"linkcolor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 - Create one file with all graphs using \"merge_graphs\" \n",
    "in the required DataDIVR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graphs = [G_rgba, G_hex, G_clusters, G_hex8]\n",
    "G_merged = merge_graphs(Graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Or take old JSON files and merge into one as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import glob\n",
    "\n",
    "# def transform_annotation(annotation_list):\n",
    "#     \"\"\"\n",
    "#     Transforms a list containing a single string of annotations into a dictionary.\n",
    "#     The string is expected to contain annotations separated by '/',\n",
    "#     with each annotation in the format 'key: value'.\n",
    "#     Example input: ['ID: 1/degree: 10']\n",
    "#     Example output: {'ID': '1', 'degree': '10'}\n",
    "#     \"\"\"\n",
    "#     annotation_dict = {}\n",
    "#     if annotation_list:  # Check if the list is not empty\n",
    "#         annotations = annotation_list[0].split('/')\n",
    "#         for annotation in annotations:\n",
    "#             key, value = annotation.split(': ', 1)  # Split on the first occurrence of ': '\n",
    "#             annotation_dict[key.strip()] = value.strip()\n",
    "#     return annotation_dict\n",
    "\n",
    "# def merge_old_json_structure(file_paths):\n",
    "#     all_nodes = []\n",
    "#     all_links = []\n",
    "#     layouts = []\n",
    "\n",
    "#     for file_path in file_paths:\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             data = json.load(file)\n",
    "\n",
    "#             # Process nodes for global and layout-specific lists\n",
    "#             for node in data[\"nodes\"]:\n",
    "#                 if \"annotation\" in node and isinstance(node[\"annotation\"], list):\n",
    "#                     node[\"annotation\"] = transform_annotation(node[\"annotation\"])\n",
    "#                 all_nodes.append({'id': node['id'], 'annotation': node.get('annotation', {})})\n",
    "\n",
    "#             # Process links for global list, now with separate source and target\n",
    "#             for link in data[\"links\"]:\n",
    "#                 all_links.append({\n",
    "#                     'source': link['source'],\n",
    "#                     'target': link['target']\n",
    "#                 })\n",
    "\n",
    "#             # Prepare layout-specific nodes and links\n",
    "#             layout_nodes = [{'nodecolor': node.get('nodecolor', ''),\n",
    "#                              'pos': node.get('pos', []),\n",
    "#                              'id': node['id']} for node in data[\"nodes\"]]\n",
    "#             layout_links = [{'linkcolor': link.get('linkcolor', ''),\n",
    "#                              'source': link['source'],\n",
    "#                              'target': link['target']} for link in data[\"links\"]]\n",
    "\n",
    "#             layouts.append({'nodes': layout_nodes, 'links': layout_links})\n",
    "\n",
    "#     # Use the structure of the first file as the base for the merged structure\n",
    "#     merged_structure = {}\n",
    "#     if file_paths:\n",
    "#         with open(file_paths[0], 'r') as file:\n",
    "#             base_structure = json.load(file)\n",
    "#             # Extract graph properties directly to the top level, not nested under 'graph'\n",
    "#             graph_info = base_structure.get('graph', {})\n",
    "#             for key, value in graph_info.items():\n",
    "#                 merged_structure[key] = value\n",
    "\n",
    "#             # Set other top-level keys\n",
    "#             merged_structure['directed'] = base_structure.get('directed', False)\n",
    "#             merged_structure['multigraph'] = base_structure.get('multigraph', False)\n",
    "\n",
    "#     # Add the global nodes and links, and the layouts to the merged structure\n",
    "#     merged_structure['nodes'] = all_nodes\n",
    "#     merged_structure['links'] = all_links\n",
    "#     merged_structure['layouts'] = layouts\n",
    "\n",
    "#     return merged_structure\n",
    "\n",
    "\n",
    "# # old project ( old JSON format) \n",
    "# folder = \"temp_upload_data/\"\n",
    "# subfolder = \"cube\"\n",
    "# file_paths = glob.glob(folder + subfolder + '/' + '*.json')\n",
    "# merged_json = merge_old_json_structure(file_paths)\n",
    "\n",
    "# # Save the merged JSON to a file\n",
    "# with open(folder + 'merged.json', 'w') as outfile:\n",
    "#     json.dump(merged_json, outfile, indent=4)\n",
    "\n",
    "# print(\"Merged JSON saved as 'merged.json'.\")\n",
    "\n",
    "# merged_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 - CREATE PROJECT - for DataDiVR BACKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory static/projects/_uploadtest-4-sceneskey \n",
      "CDEBUG: created folder and pfile.json\n",
      "C_DEBUG: pfile :  {'name': '_uploadtest-4-sceneskey', 'layouts': [], 'layoutsRGB': [], 'links': [], 'linksRGB': [], 'selections': [], 'scenes': []}\n",
      "['_uploadtest-4-sceneskey', 'JSON_barbellgraph', 'JSON_autocore', '_uploadtest-2', 'JSON_Zachary', '_uploadtest-3', 'ToyNetwork_2', 'ToyNetwork_geometric-new', '_uploadtest-1', 'ToyNetwork_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<a style=\"color:green;\">SUCCESS </a>LayoutID0 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID1 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID2 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID3 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID0 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID1 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID2 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID3 Node Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID0 Link Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID1 Link Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID2 Link Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID3 Link Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID0_links Link Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID1_links Link Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID2_links Link Textures Created<br><a style=\"color:green;\">SUCCESS </a>LayoutID3_links Link Textures Created<br>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uploaderGraph import upload_filesJSON\n",
    "\n",
    "upload_filesJSON(G_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hypersphere_datanet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
