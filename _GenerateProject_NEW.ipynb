{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GENERATE BACKEND PROJECT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json \n",
    "import os\n",
    "\n",
    "G = nx.random_geometric_graph(100,0.25)\n",
    "print(\"Number of nodes: \", len(G.nodes()))\n",
    "print(\"Number of Links: \", len(G.edges()))\n",
    "\n",
    "# generate graph layouts i.e. node positions \n",
    "posG3D_1_pre = nx.spring_layout(G, dim=3, k=0.1, iterations=100)\n",
    "posG3D_1 = {key: value.tolist() for key, value in posG3D_1_pre.items()}\n",
    "\n",
    "posG3D_2_pre = nx.spring_layout(G, dim=3, k=0.1, iterations=200)\n",
    "posG3D_2= {key: value.tolist() for key, value in posG3D_2_pre.items()}\n",
    "\n",
    "posG3D_3_pre =nx.spring_layout(G, dim=3, k=0.1, iterations=500)\n",
    "posG3D_3 = {key: value.tolist() for key, value in posG3D_3_pre.items()}\n",
    "\n",
    "# hex color values \n",
    "d_nodecolors_hex = dict(zip(G.nodes(),['#FF2300']*len(G.nodes())))\n",
    "l_linkcolors_hex = '#ff0000'\n",
    "\n",
    "# rgba color values\n",
    "d_nodecolors_rgba = dict(zip(G.nodes(),[(255,35,0,120)]*len(G.nodes())))\n",
    "l_linkcolors_rgba = (0,255,0,100)\n",
    "\n",
    "# hex8 color values\n",
    "d_nodecolors_hex8 = dict(zip(G.nodes(),['#0000ffaa']*len(G.nodes())))\n",
    "l_linkcolors_hex8 = '#0080ffaa'\n",
    "\n",
    "# ===============================================\n",
    "# ANNOTATIONS - new ! (dictionary)\n",
    "# ===============================================\n",
    "l_annotations_json = []\n",
    "d_degree = dict(G.degree())\n",
    "d_eigen = dict(nx.eigenvector_centrality(G))\n",
    "for g in G.nodes():\n",
    "    sublist = {\"Node\":g, \"Degree\":d_degree[g], \"Eigenv\": round(d_eigen[g],2)}\n",
    "    l_annotations_json.append(sublist)\n",
    "        \n",
    "d_annotations = dict(zip(G.nodes(), l_annotations_json))\n",
    "nx.set_node_attributes(G, d_annotations, name=\"annotation\")\n",
    "\n",
    "import random\n",
    "cat_names = [\n",
    "    \"Whiskers\", \"Bella\", \"Loki\", \"Oliver\", \n",
    "    \"Leo\", \"Milo\", \"Charlie\", \"Max\", \n",
    "    \"Simba\", \"Luna\", \"Nala\", \"Oscar\", \n",
    "    \"Shadow\", \"Gracie\", \"Molly\", \"Tigger\"\n",
    "]\n",
    "def generate_random_cat_names(n):\n",
    "    return random.choices(cat_names, k=n)\n",
    "nodenames = generate_random_cat_names(len(G.nodes())) # these could be context specific\n",
    "\n",
    "# ===============================================\n",
    "# GRAPH NAME AND DESCRIPTION - a string each\n",
    "# ===============================================\n",
    "G.name = \"ToyNetwork\"\n",
    "G.graph['graphtitle'] = G.name\n",
    "G.graph['graphdesc'] = \"A toy graph for testing purposes. Number of nodes: \"+str(len(G.nodes()))+\", Links: \"+ str(len(G.edges()))+\".\"\n",
    "\n",
    "\n",
    "# ===============================================\n",
    "# NODE COLORS - a dict with keys = node id as in G.nodes and values = color as hex or rgba\n",
    "# LINK COLORS - a list of hex or rgba colors per edge as in G.edges or one color for all edges\n",
    "# ===============================================\n",
    "#                     a n d \n",
    "# ===============================================\n",
    "# NODE POSITIONS - a dict with keys = G.nodes and values = coordinates (x,y) or (x,y,z)\n",
    "# ===============================================\n",
    "\n",
    "# first Layout - rgba\n",
    "G_rgba = G.copy()\n",
    "G_rgba.name = '01-graph-rgbacolors'\n",
    "nx.set_node_attributes(G_rgba, d_nodecolors_rgba, name=\"nodecolor\")\n",
    "nx.set_edge_attributes(G_rgba, l_linkcolors_rgba, name=\"linkcolor\")\n",
    "nx.set_node_attributes(G_rgba, posG3D_1, name=\"pos\")\n",
    "\n",
    "# second Layout - hex\n",
    "G_hex = G.copy()\n",
    "G_hex.name = '02-graph-hexcolors'\n",
    "nx.set_node_attributes(G_hex, d_nodecolors_hex, name=\"nodecolor\")\n",
    "nx.set_edge_attributes(G_hex, l_linkcolors_hex, name=\"linkcolor\")\n",
    "nx.set_node_attributes(G_hex, posG3D_2, name=\"pos\")\n",
    "\n",
    "# third Layout - hex8\n",
    "G_hex8 = G.copy()\n",
    "G_hex8.name = '03-graph-hex8colors'\n",
    "nx.set_node_attributes(G_hex8, d_nodecolors_hex8, name=\"nodecolor\")\n",
    "nx.set_edge_attributes(G_hex8, l_linkcolors_hex8, name=\"linkcolor\")\n",
    "nx.set_node_attributes(G_hex8, posG3D_3, name=\"pos\")\n",
    "\n",
    "\n",
    "# fourth layout - cluster key next level communities\n",
    "# artifical groups of graph for cluster colors \n",
    "G_clusters = G.copy()\n",
    "G_clusters.name = '04-graph-clustershex8colors'\n",
    "\n",
    "\n",
    "clustername_1 = 'group 1'\n",
    "clustername_2 = 'group 2'\n",
    "clustername_3 = 'group 3'\n",
    "\n",
    "# nodes into groups\n",
    "for g in G_clusters.nodes():\n",
    "    if g < len(G_clusters.nodes()) / 3:\n",
    "        G_clusters.nodes[g]['cluster'] = clustername_1\n",
    "    elif g < 2 * len(G_clusters.nodes()) / 3:\n",
    "        G_clusters.nodes[g]['cluster'] = clustername_2\n",
    "    else:\n",
    "        G_clusters.nodes[g]['cluster'] = clustername_3\n",
    "\n",
    "# node colors \n",
    "d_nodecolors_clusters = {}\n",
    "nodes_group1 = []\n",
    "nodes_group2 = []\n",
    "nodes_group3 = []\n",
    "for n in G_clusters.nodes(): \n",
    "    if G_clusters.nodes[n]['cluster'] == clustername_1:\n",
    "        d_nodecolors_clusters[n] = '#0000ffaa'\n",
    "        nodes_group1.append(n)\n",
    "    elif G_clusters.nodes[n]['cluster'] == clustername_2:\n",
    "        d_nodecolors_clusters[n] = '#00ff00aa'\n",
    "        nodes_group2.append(n)\n",
    "    elif G_clusters.nodes[n]['cluster'] == clustername_3:\n",
    "        d_nodecolors_clusters[n] = '#ff0000aa'\n",
    "        nodes_group3.append(n)\n",
    "\n",
    "# link colors\n",
    "d_linkcolors_clusters = {}\n",
    "for edge in G_clusters.edges():\n",
    "    if edge[0] in nodes_group1 and edge[1] in nodes_group1:\n",
    "        d_linkcolors_clusters[edge] = '#0000ffaa'\n",
    "       \n",
    "    elif edge[0] in nodes_group2 and edge[1] in nodes_group2:\n",
    "        d_linkcolors_clusters[edge] = '#00ff00aa'\n",
    "       \n",
    "    elif edge[0] in nodes_group3 and edge[1] in nodes_group3:\n",
    "        d_linkcolors_clusters[edge] = '#ff0000aa'\n",
    "       \n",
    "    else:\n",
    "        d_linkcolors_clusters[edge] = '#B1B1B150'\n",
    "\n",
    "l_linkcolors_clusters = list(d_linkcolors_clusters.values())\n",
    "\n",
    "nx.set_node_attributes(G_clusters, d_nodecolors_clusters, name=\"nodecolor\")\n",
    "nx.set_node_attributes(G_clusters, posG3D_2, name=\"pos\") # reuse the second layout\n",
    "nx.set_edge_attributes(G_clusters, {edge: color for edge, color in zip(G_clusters.edges(), l_linkcolors_clusters)}, \"linkcolor\")\n",
    "\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapt format to have one Graph file containing all layouts (nodes, links, layouts keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_graphs(graphs):\n",
    "    all_nodes = []\n",
    "    all_links = []\n",
    "    layouts = []\n",
    "\n",
    "    seen_nodes = set()  # To track seen node IDs\n",
    "    seen_links = set()  # To track seen links by a tuple of (source, target)\n",
    "\n",
    "    for graph in graphs:\n",
    "        # Process nodes for global and layout-specific lists\n",
    "        for node, attrs in graph.nodes(data=True):\n",
    "            if node not in seen_nodes:\n",
    "                annotation = attrs.get('annotation', [])\n",
    "                anntation_mod = {}\n",
    "                for k,v in annotation.items():\n",
    "                    anntation_mod[k] = [v]\n",
    "                all_nodes.append({'id': node, 'name': nodenames[node], 'annotation': anntation_mod})\n",
    "                seen_nodes.add(node)\n",
    "\n",
    "        # Process links for global list, now with separate source and target\n",
    "        for ix,(source, target, attrs) in enumerate(graph.edges(data=True)):\n",
    "            if (source, target) not in seen_links:\n",
    "                # Assuming 'weight' might be an attribute you're interested in\n",
    "                # weight = attrs.get('weight', 1)  # Example, uncomment if needed\n",
    "                all_links.append({\n",
    "                    'id': ix,  # It's unclear how 'id' is determined; might need a unique strategy\n",
    "                    # 'w': weight,  # Uncomment if using weight\n",
    "                    'source': source,\n",
    "                    'target': target\n",
    "                })\n",
    "                seen_links.add((source, target))\n",
    "\n",
    "        # Prepare layout-specific nodes and links\n",
    "        layout_nodes = [{'nodecolor': attrs.get('nodecolor', ''),\n",
    "                         'pos': attrs.get('pos', []),\n",
    "                         'cluster': attrs.get('cluster', ),\n",
    "                         'id': node} for node, attrs in graph.nodes(data=True)\n",
    "                        ]\n",
    "        layout_links = [{'linkcolor': attrs.get('linkcolor', ''),\n",
    "                         'source': source,\n",
    "                         'target': target} for source, target, attrs in graph.edges(data=True)]\n",
    "\n",
    "        layouts.append({'nodes': layout_nodes, 'links': layout_links})\n",
    "\n",
    "    # Assuming the structure of the graphs are similar, and using the first graph as the base\n",
    "    graphlayouts = [graph.name for graph in graphs]\n",
    "    merged_structure = {\n",
    "        'directed': graphs[0].is_directed(),\n",
    "        'multigraph': graphs[0].is_multigraph(),\n",
    "        'graphtitle': graphs[0].graph.get(\"graphtitle\", \"\"),\n",
    "        'graphdesc': graphs[0].graph.get(\"graphdesc\", \"\"),\n",
    "        'graphlayouts': graphlayouts,\n",
    "        'annotationTypes': True,\n",
    "        'nodes': all_nodes,\n",
    "        'links': all_links,\n",
    "        'layouts': layouts\n",
    "    }\n",
    "\n",
    "    return merged_structure\n",
    "\n",
    "Graphs = [G_rgba, G_hex, G_clusters, G_hex8]\n",
    "G_merged = merge_graphs(Graphs)\n",
    "\n",
    "\n",
    "# Graph Format:\n",
    "G_merged[\"layouts\"][2][\"nodes\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or take old JSON files and merge into one as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import glob\n",
    "\n",
    "# def transform_annotation(annotation_list):\n",
    "#     \"\"\"\n",
    "#     Transforms a list containing a single string of annotations into a dictionary.\n",
    "#     The string is expected to contain annotations separated by '/',\n",
    "#     with each annotation in the format 'key: value'.\n",
    "#     Example input: ['ID: 1/degree: 10']\n",
    "#     Example output: {'ID': '1', 'degree': '10'}\n",
    "#     \"\"\"\n",
    "#     annotation_dict = {}\n",
    "#     if annotation_list:  # Check if the list is not empty\n",
    "#         annotations = annotation_list[0].split('/')\n",
    "#         for annotation in annotations:\n",
    "#             key, value = annotation.split(': ', 1)  # Split on the first occurrence of ': '\n",
    "#             annotation_dict[key.strip()] = value.strip()\n",
    "#     return annotation_dict\n",
    "\n",
    "# def merge_old_json_structure(file_paths):\n",
    "#     all_nodes = []\n",
    "#     all_links = []\n",
    "#     layouts = []\n",
    "\n",
    "#     for file_path in file_paths:\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             data = json.load(file)\n",
    "\n",
    "#             # Process nodes for global and layout-specific lists\n",
    "#             for node in data[\"nodes\"]:\n",
    "#                 if \"annotation\" in node and isinstance(node[\"annotation\"], list):\n",
    "#                     node[\"annotation\"] = transform_annotation(node[\"annotation\"])\n",
    "#                 all_nodes.append({'id': node['id'], 'annotation': node.get('annotation', {})})\n",
    "\n",
    "#             # Process links for global list, now with separate source and target\n",
    "#             for link in data[\"links\"]:\n",
    "#                 all_links.append({\n",
    "#                     'source': link['source'],\n",
    "#                     'target': link['target']\n",
    "#                 })\n",
    "\n",
    "#             # Prepare layout-specific nodes and links\n",
    "#             layout_nodes = [{'nodecolor': node.get('nodecolor', ''),\n",
    "#                              'pos': node.get('pos', []),\n",
    "#                              'id': node['id']} for node in data[\"nodes\"]]\n",
    "#             layout_links = [{'linkcolor': link.get('linkcolor', ''),\n",
    "#                              'source': link['source'],\n",
    "#                              'target': link['target']} for link in data[\"links\"]]\n",
    "\n",
    "#             layouts.append({'nodes': layout_nodes, 'links': layout_links})\n",
    "\n",
    "#     # Use the structure of the first file as the base for the merged structure\n",
    "#     merged_structure = {}\n",
    "#     if file_paths:\n",
    "#         with open(file_paths[0], 'r') as file:\n",
    "#             base_structure = json.load(file)\n",
    "#             # Extract graph properties directly to the top level, not nested under 'graph'\n",
    "#             graph_info = base_structure.get('graph', {})\n",
    "#             for key, value in graph_info.items():\n",
    "#                 merged_structure[key] = value\n",
    "\n",
    "#             # Set other top-level keys\n",
    "#             merged_structure['directed'] = base_structure.get('directed', False)\n",
    "#             merged_structure['multigraph'] = base_structure.get('multigraph', False)\n",
    "\n",
    "#     # Add the global nodes and links, and the layouts to the merged structure\n",
    "#     merged_structure['nodes'] = all_nodes\n",
    "#     merged_structure['links'] = all_links\n",
    "#     merged_structure['layouts'] = layouts\n",
    "\n",
    "#     return merged_structure\n",
    "\n",
    "\n",
    "# # old project ( old JSON format) \n",
    "# folder = \"temp_upload_data/\"\n",
    "# subfolder = \"cube\"\n",
    "# file_paths = glob.glob(folder + subfolder + '/' + '*.json')\n",
    "# merged_json = merge_old_json_structure(file_paths)\n",
    "\n",
    "# # Save the merged JSON to a file\n",
    "# with open(folder + 'merged.json', 'w') as outfile:\n",
    "#     json.dump(merged_json, outfile, indent=4)\n",
    "\n",
    "# print(\"Merged JSON saved as 'merged.json'.\")\n",
    "\n",
    "# merged_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataDiVR BACKEND PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uploaderGraph import upload_filesJSON\n",
    "\n",
    "upload_filesJSON(G_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code snippets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#\n",
    "# make nodes json\n",
    "#\n",
    "####################################\n",
    "\n",
    "def create_nodesjson(graph):\n",
    "    nodes = {\"nodes\": []}\n",
    "    for node, attrs in enumerate(graph[\"nodes\"]):\n",
    "        # Initialize a dictionary for attrlist\n",
    "        attrlist = {}\n",
    "        # Iterate through all attributes\n",
    "        for key, value in attrs.items():\n",
    "            # check for annotation key\n",
    "            if key == \"annotation\":\n",
    "                # Check if the value is already a list\n",
    "                if isinstance(value, list):\n",
    "                    attrlist[key] = value\n",
    "                elif isinstance(value, dict):\n",
    "                    # For dictionaries, iterate through inner keys\n",
    "                    for inner_key, inner_value in value.items():\n",
    "                        # Ensure each inner key maps to a list\n",
    "                        if inner_key not in attrlist:\n",
    "                            attrlist[inner_key] = [inner_value]\n",
    "                        else:\n",
    "                            attrlist[inner_key].append(inner_value)\n",
    "                else:\n",
    "                    # For non-list and non-dict attributes, create or append to a list\n",
    "                    if key not in attrlist:\n",
    "                        attrlist[key] = [value]\n",
    "                    else:\n",
    "                        attrlist[key].append(value)\n",
    "            \n",
    "        # Constructing node data\n",
    "        node_data = {\n",
    "            \"id\": node,\n",
    "            \"annotation\": attrlist,\n",
    "            \"n\": f\"node {node}\"\n",
    "        }\n",
    "        nodes[\"nodes\"].append(node_data)\n",
    "    return nodes\n",
    "\n",
    "\n",
    "nodes_for_json = create_nodesjson(G_merged)\n",
    "with open(path + projectname + '/nodes.json', 'w') as outfile:\n",
    "    json.dump(nodes_for_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#\n",
    "# make links.json \n",
    "#\n",
    "####################################\n",
    "\n",
    "def create_linksjson(graph):\n",
    "    links = {\"links\": []}\n",
    "    for each_edge in graph[\"links\"]: \n",
    "        links[\"links\"].append({\"id\": each_edge['id'], \"s\": each_edge['s'], \"e\": each_edge['e']})\n",
    "    return links\n",
    "\n",
    "links_for_json = create_linksjson(G_merged)\n",
    "with open(path + projectname + '/links.json', 'w') as outfile:\n",
    "    json.dump(links_for_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#\n",
    "# make textures\n",
    "#\n",
    "####################################\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from math import cos, radians, sin, sqrt\n",
    "\n",
    "from uploaderGraph import hex_to_rgb, hex_to_rgba\n",
    "from uploader import normalize_xyz, geodetic_to_geocentric\n",
    "\n",
    "\n",
    "def makeXYZTexture_G(project, nodepos, name=None): \n",
    "\n",
    "    hight = 128 * (int((len(nodepos)) / 16384) + 1)\n",
    "\n",
    "    size = 128 * hight \n",
    "    path = 'static/projects/' + project \n",
    "    \n",
    "    texh = [(0,0,0)] * size\n",
    "    texl = [(0,0,0)] * size\n",
    "\n",
    "    if \"_geo\" in name:\n",
    "        #print(\"is geo\")\n",
    "        unscaled = []\n",
    "        # convert lat lon to XYZ\n",
    "        for x in nodepos:\n",
    "            unscaled.append(geodetic_to_geocentric(float(x[0]), float(x[1])))\n",
    "        # Normalize to 0-1 range\n",
    "        scaled = normalize_xyz(unscaled)\n",
    "        \n",
    "        for i in range(len(scaled[0])):\n",
    "            \n",
    "            x = int(float(scaled[0][i])*65280)\n",
    "            y = int(float(scaled[1][i])*65280)\n",
    "            z = int(float(scaled[2][i])*65280)\n",
    "\n",
    "            xh = int(x / 255)\n",
    "            yh = int(y / 255)\n",
    "            zh = int(z / 255)\n",
    "\n",
    "            xl = x % 255\n",
    "            yl = y % 255\n",
    "            zl = z % 255\n",
    "\n",
    "            pixelh = (xh,yh,zh)\n",
    "            pixell = (xl,yl,zl)\n",
    "\n",
    "            texh[i] = pixelh\n",
    "            texl[i] = pixell\n",
    "    \n",
    "    else:\n",
    "       \n",
    "        x_norm = []\n",
    "        y_norm = []\n",
    "        z_norm = []\n",
    "        for i in range(len(nodepos)):\n",
    "                \n",
    "            x = float(nodepos[i][0])\n",
    "            y = float(nodepos[i][1])\n",
    "            z = float(nodepos[i][2])\n",
    "            \n",
    "            x_norm.append(x)\n",
    "            y_norm.append(y)\n",
    "            z_norm.append(z)\n",
    "\n",
    "        # check on coordinates - if normalized        \n",
    "        if min(x_norm)<0 or min(y_norm)<0 or min(z_norm)<0 or max(x_norm)>1 or max(y_norm)>1 or max(z_norm)>1:\n",
    "            coordinates_norm = normalize_xyz(nodepos) \n",
    "            for i in range(len(coordinates_norm[0])):\n",
    "                        \n",
    "                x = int(float(coordinates_norm[0][i])*65280)\n",
    "                y = int(float(coordinates_norm[1][i])*65280)\n",
    "                z = int(float(coordinates_norm[2][i])*65280)\n",
    "\n",
    "                xh = int(x / 255)\n",
    "                yh = int(y / 255)\n",
    "                zh = int(z / 255)\n",
    "\n",
    "                xl = x % 255\n",
    "                yl = y % 255\n",
    "                zl = z % 255\n",
    "\n",
    "                pixelh = (xh,yh,zh)\n",
    "                pixell = (xl,yl,zl)\n",
    "\n",
    "                texh[i] = pixelh\n",
    "                texl[i] = pixell\n",
    "\n",
    "        else:\n",
    "            for i in range(len(nodepos)):\n",
    "\n",
    "                x = int(float(nodepos[i][0])*65280)\n",
    "                y = int(float(nodepos[i][1])*65280)\n",
    "                z = int(float(nodepos[i][2])*65280)\n",
    "\n",
    "                xh = int(x / 255)\n",
    "                yh = int(y / 255)\n",
    "                zh = int(z / 255)\n",
    "\n",
    "                xl = x % 255\n",
    "                yl = y % 255\n",
    "                zl = z % 255\n",
    "\n",
    "                pixelh = (xh,yh,zh)\n",
    "                pixell = (xl,yl,zl)\n",
    "\n",
    "                texh[i] = pixelh\n",
    "                texl[i] = pixell\n",
    "                #print(pixelh)\n",
    "                #print(\"C_DEBUG: DID NOT normalize coordinates.\")\n",
    "\n",
    "    new_imgh = Image.new('RGB', (128, hight))\n",
    "    new_imgl = Image.new('RGB', (128, hight))\n",
    "\n",
    "    new_imgh.putdata(texh)\n",
    "    new_imgl.putdata(texl)\n",
    "\n",
    "    pathXYZ = path + '/layouts/' +  str(name) + 'XYZ.bmp'\n",
    "    pathXYZl = path + '/layoutsl/' + str(name) + 'XYZl.bmp' \n",
    "    #if name is not None:\n",
    "    #    pathXYZ = path + '/layouts/' +  str(name) + '.bmp'\n",
    "    #    pathXYZl = path + '/layoutsl/' +  str(name)  + 'l.bmp' \n",
    "\n",
    "    if os.path.exists(pathXYZ):\n",
    "        return '<a style=\"color:red;\">ERROR </a>' + str(name) + \" Nodelist already in project\"\n",
    "    else:\n",
    "        new_imgh.save(pathXYZ)\n",
    "        new_imgl.save(pathXYZl)\n",
    "        return '<a style=\"color:green;\">SUCCESS </a>' + str(name) + \" Node Textures Created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def makeNodeRGBTexture_G(project, nodecolors, name): \n",
    "    \n",
    "    rgba_colors = []\n",
    "\n",
    "    # check if data is rgba or hex string\n",
    "    for i,color in enumerate(nodecolors):\n",
    "\n",
    "        if isinstance(color, str):  \n",
    "            # if HEX FORMAT\n",
    "            if re.match(r'^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})$', color):\n",
    "                _r, _g, _b = hex_to_rgb(color)\n",
    "                rgba_color = (_r, _g, _b, 100)\n",
    "                rgba_colors.append(rgba_color)\n",
    "\n",
    "            # if HEX FORMAT with alpha\n",
    "            elif re.match(r'^#([A-Fa-f0-9]{8})$', color):\n",
    "                rgba_color = hex_to_rgba(color)\n",
    "                rgba_colors.append(rgba_color)\n",
    "\n",
    "            # if RGBA FORMAT\n",
    "            elif re.match(r'^rgba\\((\\d+),(\\d+),(\\d+),(\\d+)\\)$', color) or re.match(r'^\\((\\d+),(\\d+),(\\d+),(\\d+)\\)$', color) or re.match(r'^RGBA\\((\\d+),(\\d+),(\\d+),(\\d+)\\)$', color):\n",
    "                rgba = re.findall(r'\\d+', color)\n",
    "                rgba_color = tuple(map(int, rgba))\n",
    "                rgba_colors.append(rgba_color)\n",
    "\n",
    "            elif isinstance(color, tuple) and len(color) == 4:\n",
    "                #print(\"C_DEBUG: link color is tuple\")  \n",
    "                rgba_colors.append(color)\n",
    "            \n",
    "            elif isinstance(color, list) and len(color) == 4:\n",
    "                #print(\"C_DEBUG: link color is list\")  \n",
    "                rgba_colors.append(tuple(color))\n",
    "\n",
    "            else:\n",
    "                print(\"C_DEBUG: NO rgba_colors FOUND\")\n",
    "                rgba_colors.append((255, 0, 255, 100))\n",
    "            \n",
    "        else:   \n",
    "            rgba_colors.append(color)\n",
    "\n",
    "    hight = 128 * (int((len(nodecolors)) / 16384) + 1)\n",
    "\n",
    "    size = 128 * hight \n",
    "    path = 'static/projects/' + project \n",
    "    tex = [(128,0,0,100)] * size\n",
    "\n",
    "    for i in range(len(rgba_colors)): #pixeldata[\"data\"])):\n",
    "        tex[i] = (int(rgba_colors[i][0]), int(rgba_colors[i][1]),int(rgba_colors[i][2]),int(rgba_colors[i][3]))\n",
    "\n",
    "    new_img = Image.new('RGBA', (128, hight))\n",
    "    new_img.putdata(tex)\n",
    "    pathXYZ = path + '/layoutsRGB/' +  str(name) +  'RGB.png'\n",
    "\n",
    "    if os.path.exists(pathXYZ):\n",
    "        return print(\"Already in project: \" + name) #'<a style=\"color:red;\">ERROR </a>' + str(name)  + \" colors already in project\"\n",
    "    else:\n",
    "        new_img.save(pathXYZ , \"PNG\")\n",
    "        return print(\"Done with bitmap: \" + name) #'<a style=\"color:green;\">SUCCESS </a>' + str(name)  + \" Node Textures Created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layouts_nodes = {}\n",
    "layouts_links = {}\n",
    "for name,layout in zip(G_merged[\"graphlayouts\"],G_merged[\"layouts\"]):\n",
    "    layouts_nodes[name] = layout[\"nodes\"]\n",
    "    layouts_links[name] = layout[\"links\"]\n",
    "\n",
    "# layout positions and RGB colors\n",
    "for name,layout in layouts_nodes.items():\n",
    "    d_nodepos = {node[\"id\"]: node[\"pos\"] for node in layout}\n",
    "    nodepos = list(d_nodepos.values())\n",
    "    makeXYZTexture_G(projectname, nodepos, name)\n",
    "\n",
    "    d_nodecol = {node[\"id\"]: node[\"nodecolor\"] for node in layout}\n",
    "    nodecolors = list(d_nodecol.values())\n",
    "    makeNodeRGBTexture_G(projectname, nodecolors, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLinkTex_G(project, links, name): \n",
    "\n",
    "    hight = 64 * (int((len(links)) / 32768) + 1)\n",
    "    path = 'static/projects/' + project \n",
    "\n",
    "    texl = [(0,0,0)] * 1024 * hight\n",
    "    new_imgl = Image.new('RGB', (1024, hight))\n",
    "    i = 0\n",
    "\n",
    "    linklist = {}\n",
    "    linklist[\"links\"] = []\n",
    "    try:\n",
    "        for row in links:\n",
    "            thislink = {}\n",
    "            thislink[\"id\"] = i\n",
    "            thislink[\"source\"] = row[0]\n",
    "            thislink[\"target\"] = row[1]\n",
    "            linklist[\"links\"].append(thislink)\n",
    "\n",
    "            sx = int(row[0]) % 128 # R\n",
    "            syl = int(int(row[0]) / 128) % 128 # G\n",
    "            syh = int(int(row[0]) / 16384) # B\n",
    "\n",
    "            ex = int(row[1]) % 128\n",
    "            eyl = int(int(row[1]) / 128) % 128\n",
    "            eyh = int(int(row[1]) / 16384)\n",
    "\n",
    "\n",
    "            pixell1 = (sx,syl,syh)\n",
    "            pixell2 = (ex,eyl,eyh)\n",
    "\n",
    "            #if i < 262144:\n",
    "\n",
    "            texl[i*2] = pixell1\n",
    "            texl[i*2+1] = pixell2\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    except (IndexError, ValueError):\n",
    "        return print(\"Error. Linkfile \" + name + \" seems malformated.\")#'<a style=\"color:red;\">ERROR </a>'  +  links[\"name\"] + \" Linkfile malformated?\" \n",
    "\n",
    "    new_imgl.putdata(texl)\n",
    "    pathl = path + '/links/' +  name +  '_linksXYZ.bmp'\n",
    "\n",
    "    if os.path.exists(pathl):\n",
    "        return '<a style=\"color:red;\">ERROR </a>' +  name  + \" linklist already in project\"\n",
    "    else:\n",
    "        new_imgl.save(pathl)\n",
    "        return '<a style=\"color:green;\">SUCCESS </a>' +  name +  \" Link Textures Created\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLinkRGBTex_G(project, linksRGB, name=None):\n",
    "    \n",
    "    hight = 64 * (int((len(linksRGB)) / 32768) + 1)\n",
    "    path = 'static/projects/' + project \n",
    "    rgba_colors = []\n",
    "    # check if data is rgba or hex string\n",
    "    try:\n",
    "        for color in linksRGB:\n",
    "            if isinstance(color, str):\n",
    "                \n",
    "                # if HEX FORMAT\n",
    "                if re.match(r'^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})$', color):\n",
    "                    #print(\"C_DEBUG: link color is hex\")\n",
    "                    _r, _g, _b = hex_to_rgb(color)\n",
    "                    rgba_color = (_r, _g, _b, 100)\n",
    "                    rgba_colors.append(rgba_color)\n",
    "\n",
    "                # if HEX FORMAT with alpha\n",
    "                elif re.match(r'^#([A-Fa-f0-9]{8})$', color):\n",
    "                    #print(\"C_DEBUG: link color is hex with alpha\")\n",
    "                    rgba_color = hex_to_rgba(color)\n",
    "                    rgba_colors.append(rgba_color)\n",
    "\n",
    "                # if RGBA FORMAT\n",
    "                elif re.match(r'^rgba\\((\\d+),(\\d+),(\\d+),(\\d+)\\)$', color) or re.match(r'^\\((\\d+),(\\d+),(\\d+),(\\d+)\\)$', color) or re.match(r'^RGBA\\((\\d+),(\\d+),(\\d+),(\\d+)\\)$', color):\n",
    "                    #print(\"C_DEBUG: link color is rgba\")\n",
    "                    rgba = re.findall(r'\\d+', color)\n",
    "                    rgba_color = tuple(map(int, rgba))\n",
    "                    rgba_colors.append(rgba_color)\n",
    "\n",
    "            elif isinstance(color, tuple) and len(color) == 4:\n",
    "                #print(\"C_DEBUG: link color is tuple\")  \n",
    "                rgba_colors.append(color)\n",
    "            \n",
    "            elif isinstance(color, list) and len(color) == 4:\n",
    "                #print(\"C_DEBUG: link color is list\")  \n",
    "                rgba_colors.append(tuple(color))\n",
    "\n",
    "            else:\n",
    "                #print(\"C_DEBUG: NO LINKCOLOR FOUND\")\n",
    "                rgba_colors.append((255, 0, 255, 100))\n",
    "    except:\n",
    "        print(\"has no colors\")\n",
    "\n",
    "    texc = [(0,0,0,0)] * 512 * hight\n",
    "\n",
    "    new_imgc = Image.new('RGBA', (512, hight))\n",
    "    i = 0\n",
    "\n",
    "    linklist = {}\n",
    "    linklist[\"links\"] = []\n",
    "    try:\n",
    "        for row in rgba_colors: \n",
    "            #if i < 262144:\n",
    "            texc[i]  = (int(row[0]),int(row[1]),int(row[2]),int(row[3]))\n",
    "            i += 1\n",
    "\n",
    "    except (IndexError, ValueError):\n",
    "        return print(\"Error. Linkfile \" + name + \" seems malformated.\") #'<a style=\"color:red;\">ERROR </a>'  +  linksRGB[\"name\"] + \" Linkfile malformated?\" \n",
    "\n",
    "    new_imgc.putdata(texc)\n",
    "    pathRGB = path + '/linksRGB/' +  name +  '_linksRGB.png'\n",
    "\n",
    "    if os.path.exists(pathRGB):\n",
    "        return print(\"Error. \" +  name + \" linklist already in project.\") #'<a style=\"color:red;\">ERROR </a>' +  linksRGB[\"name\"]  + \" linklist already in project\"\n",
    "    else:\n",
    "        new_imgc.save(pathRGB, \"PNG\")\n",
    "        return print(\"Success. \" +  name +  \" Link Textures Created\") #'<a style=\"color:green;\">SUCCESS </a>' +  linksRGB[\"name\"] +  \" Link Textures Created\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,links in layouts_links.items():\n",
    "    linklist = list((link[\"s\"], link[\"e\"]) for link in links)\n",
    "    makeLinkTex_G(projectname, linklist, name)\n",
    "\n",
    "    linkcolors = [i[\"linkcolor\"] for i in links]\n",
    "    makeLinkRGBTex_G(projectname, linkcolors, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLinksjsonperLayout_G(project,links, name):\n",
    "    path = 'static/projects/' + project \n",
    "\n",
    "    all_links = {}\n",
    "    for ix,l in enumerate(links):\n",
    "\n",
    "        linksperlayout = []\n",
    "        for subdict in l:        \n",
    "            i = 0\n",
    "\n",
    "            sublist = []\n",
    "            try:\n",
    "                for row in subdict: #[\"data\"]:\n",
    "                    thislink = {}\n",
    "\n",
    "                    thislink[\"id\"] = i\n",
    "                    thislink[\"s\"] = row[0]\n",
    "                    thislink[\"e\"] = row[1]\n",
    "\n",
    "\n",
    "                    #------------------------------------------------------------------------------\n",
    "                    # TO DO \n",
    "                    # here comes info e.g. COLOR \"c\" and WEIGHT \"w\" and DIRECTION \"d\" per link\n",
    "                    #------------------------------------------------------------------------------\n",
    "\n",
    "                    sublist.append(thislink)\n",
    "                    i += 1\n",
    "            \n",
    "            except (IndexError, ValueError):\n",
    "                return print(\"Error. Linkfile \" + name + \" seems malformated.\") #'<a style=\"color:red;\">ERROR </a>'  +  subdict[\"name\"] + \" Linkfile malformated?\" \n",
    "            \n",
    "            linksperlayout.append(sublist)\n",
    "\n",
    "    all_links[\"links\"] = linksperlayout\n",
    "\n",
    "    with open(path + '/linkslayouts.json', 'w') as outfile:\n",
    "        json.dump(all_links, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pfile \n",
    "\n",
    "pfile = {}\n",
    "pfile[\"name\"] = projectname\n",
    "pfile[\"layouts\"] = []\n",
    "pfile[\"layoutsRGB\"] = []\n",
    "pfile[\"links\"] = []\n",
    "pfile[\"linksRGB\"] = []\n",
    "pfile[\"selections\"] = []\n",
    "\n",
    "pfile[\"graphtitle\"] = G_merged[\"graphtitle\"]\n",
    "pfile[\"graphdesc\"] = G_merged[\"graphdesc\"]\n",
    "pfile[\"legendfiles\"] = []\n",
    "pfile[\"annotationTypes\"] = False\n",
    "\n",
    "folder = 'static/projects/' + projectname + '/'\n",
    "\n",
    "pfile[\"linkcount\"] = len(G_merged[\"links\"])\n",
    "pfile[\"nodecount\"] = len(G_merged[\"nodes\"])\n",
    "# ?? pfile[\"selections\"].append({\"name\":name, \"nodes\":row, \"layoutname\": labellist[\"name\"]}) \n",
    "for i in G_merged[\"graphlayouts\"]:\n",
    "    pfile[\"layouts\"].append(i + \"XYZ\") \n",
    "    pfile[\"layoutsRGB\"].append(i + \"RGB\")\n",
    "    pfile[\"links\"].append(i + \"_linksXYZ\")\n",
    "    pfile[\"linksRGB\"].append(i + \"_linksRGB\")\n",
    "\n",
    "with open(folder + '/pfile.json', 'w') as outfile:\n",
    "    json.dump(pfile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hypersphere_datanet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
